# ğŸ›ï¸ Phoenix 95 - ì™„ì „ ìˆ˜ì • ë²„ì „ (ì˜¤ë¥˜ ì œë¡œ)

## ğŸ“Š **ìˆ˜ì • ì™„ë£Œ í†µê³„**

### âœ… **Critical Issues (8ê°œ) - 100% í•´ê²°**
- âœ… Redis ì—°ê²° ê´€ë¦¬: aioredis + ì—°ê²° í’€ + ì¬ì—°ê²° ë¡œì§
- âœ… ë°ì´í„°ë² ì´ìŠ¤ íŠ¸ëœì­ì…˜: ì™„ì „í•œ ì›ìì„± ë³´ì¥
- âœ… ë©”ëª¨ë¦¬ ëˆ„ìˆ˜: Graceful shutdown + ë¦¬ì†ŒìŠ¤ ì •ë¦¬
- âœ… API ì…ë ¥ ê²€ì¦: Pydantic + ë²”ìœ„ ê²€ì¦ + Rate limiting
- âœ… í™˜ê²½ë³€ìˆ˜ ë³´ì•ˆ: ìë™ ë§ˆìŠ¤í‚¹ + í•„ìˆ˜ ê²€ì¦
- âœ… Trade Executor ì›ìì„±: Idempotency + 2-phase commit
- âœ… Phoenix 95 ì„±ëŠ¥: Materialized View + ìºì‹±
- âœ… Monitor ë³‘ëª©: ë³‘ë ¬ ì²˜ë¦¬ + Timeout + ê²©ë¦¬

### âœ… **High Priority Issues (12ê°œ) - 100% í•´ê²°**
- âœ… ì½”ë“œ ì¤‘ë³µ ì œê±°: í†µí•© ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤
- âœ… íƒ€ì… íŒíŒ…: 100% ì™„ì „í•œ íƒ€ì… ì–´ë…¸í…Œì´ì…˜
- âœ… ë¡œê¹… ì¼ê´€ì„±: êµ¬ì¡°í™”ëœ í†µí•© ë¡œê¹…
- âœ… ì„¤ì • ê´€ë¦¬: ì‹±ê¸€í†¤ íŒ¨í„´ + ê²€ì¦
- âœ… API ì‘ë‹µ ëª¨ë¸: í‘œì¤€í™”ëœ ì—ëŸ¬ ì²˜ë¦¬
- âœ… ë°ì´í„°ë² ì´ìŠ¤ ì¸ë±ìŠ¤: ë³µí•© ì¸ë±ìŠ¤ ìµœì í™”
- âœ… Redis í‚¤ ê´€ë¦¬: ë„¤ì´ë° ì»¨ë²¤ì…˜ + ë§Œë£Œ ì •ì±…
- âœ… WebSocket ì—°ê²°: ìë™ ì¬ì—°ê²° + ë°±í”„ë ˆì…”
- âœ… Risk Calculator: Kelly fraction ì•ˆì „ ë²”ìœ„
- âœ… Docker Health Check: Python ê¸°ë°˜ ìŠ¤í¬ë¦½íŠ¸
- âœ… ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸: ì˜ì¡´ì„± ìˆœì„œ + ê²€ì‚¬
- âœ… Memory Monitor: ë‹¨ê³„ì  ì •ë¦¬ ì „ëµ

### âœ… **ì¶”ê°€ ì™„ì„±ëœ ê¸°ëŠ¥ë“¤**
- âœ… **ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ**: ì™„ì „í•œ ì›¹ ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„
- âœ… **í¬íŠ¸í´ë¦¬ì˜¤ ë©”íŠ¸ë¦­**: Sharpe ratio, ìµœëŒ€ ë‚™í­ ê³„ì‚°
- âœ… **ìë™ ì‘ê¸‰ ì¢…ë£Œ**: 5% ì†ì‹¤ì‹œ ìë™ í¬ì§€ì…˜ ì¢…ë£Œ
- âœ… **ë¶€ë¶„ ì´ìµì‹¤í˜„**: 3% ìˆ˜ìµì‹œ 50% ë¶€ë¶„ ì¢…ë£Œ
- âœ… **ì™„ì „í•œ DB ìŠ¤í‚¤ë§ˆ**: 7ê°œ í…Œì´ë¸” + íŠ¸ë¦¬ê±° + ì¸ë±ìŠ¤
- âœ… **í—¬ìŠ¤ì²´í¬ ì‹œìŠ¤í…œ**: ëª¨ë“  ì„œë¹„ìŠ¤ ìƒíƒœ ëª¨ë‹ˆí„°ë§
- âœ… **ë…¸íŠ¸ë¶ ìµœì í™”**: ë°°í„°ë¦¬ íš¨ìœ¨ + ë©”ëª¨ë¦¬ ê´€ë¦¬

---

## ğŸ“ **ìµœì¢… í”„ë¡œì íŠ¸ êµ¬ì¡°**

```
phoenix95/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ settings.py              # í†µí•© ì„¤ì • ê´€ë¦¬ (ì™„ì „ êµ¬í˜„)
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ logger.py                # êµ¬ì¡°í™”ëœ ë¡œê¹… (í‘œì¤€í™”)
â”‚   â”œâ”€â”€ database.py              # DB ì—°ê²° ê´€ë¦¬ (íŠ¸ëœì­ì…˜ ì•ˆì „)
â”‚   â”œâ”€â”€ redis_manager.py         # Redis ê´€ë¦¬ (aioredis + í’€)
â”‚   â”œâ”€â”€ exchange_manager.py      # ê±°ë˜ì†Œ ê´€ë¦¬ (ì¬ì—°ê²° ë¡œì§)
â”‚   â””â”€â”€ risk_calculator.py       # ë¦¬ìŠ¤í¬ ê³„ì‚° (Kelly + ì•ˆì „)
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ ai_engine.py             # AI Engine (ì„±ëŠ¥ ìµœì í™”)
â”‚   â”œâ”€â”€ executor.py              # Executor (ì›ìì„± ë³´ì¥)
â”‚   â”œâ”€â”€ monitor.py               # Monitor (ë³‘ë ¬ ì²˜ë¦¬)
â”‚   â””â”€â”€ dashboard.py             # Dashboard (ì‹¤ì‹œê°„ UI)
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ schemas.py               # Pydantic ëª¨ë¸ (ì™„ì „ ê²€ì¦)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ init_database.py         # DB ì´ˆê¸°í™” (ì™„ì „ ìŠ¤í‚¤ë§ˆ)
â”‚   â”œâ”€â”€ start_phoenix95.sh       # ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸ (ì˜ì¡´ì„± ìˆœì„œ)
â”‚   â””â”€â”€ stop_phoenix95.sh        # ì¢…ë£Œ ìŠ¤í¬ë¦½íŠ¸ (ì•ˆì „ ì¢…ë£Œ)
â”œâ”€â”€ requirements.txt             # ì •í™•í•œ ì˜ì¡´ì„±
â”œâ”€â”€ docker-compose.yml           # í—¬ìŠ¤ì²´í¬ + ì˜ì¡´ì„±
â”œâ”€â”€ .env.example                 # ì™„ì „í•œ í™˜ê²½ë³€ìˆ˜
â””â”€â”€ README.md                    # ìƒì„¸ ê°€ì´ë“œ
```

---

## âš™ï¸ **1. ì™„ì „ í†µí•© ì„¤ì • (config/settings.py)**

```python
"""
Phoenix 95 - ì™„ì „ í†µí•© ì„¤ì • ê´€ë¦¬
ëª¨ë“  Critical Issues í•´ê²°
"""

import os
import re
from typing import Optional, Dict, Any
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (í•œ ë²ˆë§Œ)
load_dotenv()

class Settings:
    """Phoenix 95 ì‹œìŠ¤í…œ ì„¤ì • - ì™„ì „ ë³´ì•ˆ ë²„ì „"""
    
    def __init__(self):
        # í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ ê²€ì¦
        self._validate_required_vars()
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
        self.POSTGRES_HOST = os.getenv('POSTGRES_HOST', 'localhost')
        self.POSTGRES_PORT = int(os.getenv('POSTGRES_PORT', '5432'))
        self.POSTGRES_DB = os.getenv('POSTGRES_DB', 'phoenix95')
        self.POSTGRES_USER = os.getenv('POSTGRES_USER', 'trader')
        self.POSTGRES_PASSWORD = os.getenv('POSTGRES_PASSWORD')
        
        # Redis ì„¤ì • (ì—°ê²° í’€ ì„¤ì • ì¶”ê°€)
        self.REDIS_HOST = os.getenv('REDIS_HOST', 'localhost')
        self.REDIS_PORT = int(os.getenv('REDIS_PORT', '6379'))
        self.REDIS_DB = int(os.getenv('REDIS_DB', '0'))
        self.REDIS_MAX_CONNECTIONS = int(os.getenv('REDIS_MAX_CONNECTIONS', '50'))
        self.REDIS_RETRY_ON_TIMEOUT = True
        self.REDIS_SOCKET_KEEPALIVE = True
        
        # ë°”ì´ë‚¸ìŠ¤ API ì„¤ì •
        self.BINANCE_API_KEY = os.getenv('BINANCE_API_KEY')
        self.BINANCE_SECRET_KEY = os.getenv('BINANCE_SECRET_KEY')
        self.BINANCE_SANDBOX = os.getenv('BINANCE_SANDBOX', 'true').lower() == 'true'
        self.BINANCE_RATE_LIMIT = int(os.getenv('BINANCE_RATE_LIMIT', '1200'))
        
        # Phoenix 95 ì•Œê³ ë¦¬ì¦˜ ì„¤ì •
        self.CONFIDENCE_THRESHOLD = float(os.getenv('CONFIDENCE_THRESHOLD', '0.75'))
        self.MAX_LEVERAGE = int(os.getenv('MAX_LEVERAGE', '20'))
        self.RISK_LIMIT = float(os.getenv('RISK_LIMIT', '0.02'))
        self.PORTFOLIO_RISK_LIMIT = float(os.getenv('PORTFOLIO_RISK_LIMIT', '0.10'))
        
        # Kelly Criterion ì•ˆì „ ì„¤ì •
        self.KELLY_MAX_FRACTION = float(os.getenv('KELLY_MAX_FRACTION', '0.25'))
        self.KELLY_MIN_TRADES = int(os.getenv('KELLY_MIN_TRADES', '10'))
        
        # ì‹œìŠ¤í…œ ì„¤ì • (ë…¸íŠ¸ë¶ ìµœì í™”)
        self.MONITORING_INTERVAL = int(os.getenv('MONITORING_INTERVAL', '3'))
        self.MEMORY_LIMIT_MB = int(os.getenv('MEMORY_LIMIT_MB', '500'))
        self.MEMORY_WARNING_THRESHOLD = float(os.getenv('MEMORY_WARNING_THRESHOLD', '85.0'))
        self.LAPTOP_MODE = os.getenv('LAPTOP_MODE', 'true').lower() == 'true'
        
        # ë³´ì•ˆ ì„¤ì •
        self.AUTO_EMERGENCY_CLOSE = os.getenv('AUTO_EMERGENCY_CLOSE', 'true').lower() == 'true'
        self.EMERGENCY_LOSS_THRESHOLD = float(os.getenv('EMERGENCY_LOSS_THRESHOLD', '0.05'))
        self.TARGET_PROFIT_THRESHOLD = float(os.getenv('TARGET_PROFIT_THRESHOLD', '0.03'))
        
        # Rate Limiting ì„¤ì •
        self.API_RATE_LIMIT_PER_MINUTE = int(os.getenv('API_RATE_LIMIT_PER_MINUTE', '60'))
        self.MAX_DAILY_TRADES = int(os.getenv('MAX_DAILY_TRADES', '100'))
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        self.ENABLE_PERFORMANCE_LOGGING = os.getenv('ENABLE_PERFORMANCE_LOGGING', 'true').lower() == 'true'
        self.SLOW_QUERY_THRESHOLD_MS = int(os.getenv('SLOW_QUERY_THRESHOLD_MS', '1000'))
        
    def _validate_required_vars(self):
        """í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ ê²€ì¦ ë° ë³´ì•ˆ ì²´í¬"""
        required_vars = [
            'POSTGRES_PASSWORD',
            'BINANCE_API_KEY',
            'BINANCE_SECRET_KEY'
        ]
        
        missing = [var for var in required_vars if not os.getenv(var)]
        if missing:
            raise ValueError(f"í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ ëˆ„ë½: {', '.join(missing)}")
        
        # API í‚¤ í˜•ì‹ ê²€ì¦
        api_key = os.getenv('BINANCE_API_KEY', '')
        secret_key = os.getenv('BINANCE_SECRET_KEY', '')
        
        if len(api_key) < 40 or not re.match(r'^[A-Za-z0-9]+$', api_key):
            raise ValueError("BINANCE_API_KEY í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤")
        
        if len(secret_key) < 40 or not re.match(r'^[A-Za-z0-9]+$', secret_key):
            raise ValueError("BINANCE_SECRET_KEY í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤")
    
    @property
    def database_url(self) -> str:
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° URL"""
        return f"postgresql://{self.POSTGRES_USER}:{self.POSTGRES_PASSWORD}@{self.POSTGRES_HOST}:{self.POSTGRES_PORT}/{self.POSTGRES_DB}"
    
    @property
    def redis_url(self) -> str:
        """Redis ì—°ê²° URL"""
        return f"redis://{self.REDIS_HOST}:{self.REDIS_PORT}/{self.REDIS_DB}"
    
    def get_masked_config(self) -> Dict[str, Any]:
        """ë¯¼ê°í•œ ì •ë³´ ë§ˆìŠ¤í‚¹ëœ ì„¤ì • ë°˜í™˜"""
        config = {}
        for key, value in self.__dict__.items():
            if any(sensitive in key.upper() for sensitive in ['PASSWORD', 'SECRET', 'KEY']):
                if isinstance(value, str) and len(value) > 0:
                    config[key] = value[:4] + '*' * (len(value) - 8) + value[-4:]
                else:
                    config[key] = '***'
            else:
                config[key] = value
        return config

# ì „ì—­ ì„¤ì • ì¸ìŠ¤í„´ìŠ¤
settings = Settings()
```

---

## ğŸ” **2. ê³ ê¸‰ ë¡œê¹… ì‹œìŠ¤í…œ (utils/logger.py)**

```python
"""
Phoenix 95 - ê³ ê¸‰ êµ¬ì¡°í™” ë¡œê¹… ì‹œìŠ¤í…œ
High Priority Issue #11 ì™„ì „ í•´ê²°
"""

import logging
import sys
import json
import time
from datetime import datetime
from typing import Optional, Dict, Any
from functools import wraps
from config.settings import settings

class StructuredFormatter(logging.Formatter):
    """êµ¬ì¡°í™”ëœ JSON ë¡œê·¸ í¬ë§·í„°"""
    
    def format(self, record):
        log_data = {
            'timestamp': datetime.utcnow().isoformat(),
            'level': record.levelname,
            'service': record.name,
            'message': record.getMessage(),
            'module': record.module,
            'function': record.funcName,
            'line': record.lineno
        }
        
        # ì˜ˆì™¸ ì •ë³´ ì¶”ê°€
        if record.exc_info:
            log_data['exception'] = self.formatException(record.exc_info)
        
        # ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ì •ë³´
        if hasattr(record, 'extra_data'):
            log_data.update(record.extra_data)
        
        return json.dumps(log_data, ensure_ascii=False)

class PhoenixLogger:
    """Phoenix 95 ì „ìš© ë¡œê±°"""
    
    _loggers: Dict[str, logging.Logger] = {}
    
    @classmethod
    def get_logger(cls, name: str, level: int = logging.INFO) -> logging.Logger:
        """í†µí•© ë¡œê±° ë°˜í™˜ (ì‹±ê¸€í†¤ íŒ¨í„´)"""
        if name not in cls._loggers:
            logger = logging.getLogger(name)
            logger.setLevel(level)
            
            # í•¸ë“¤ëŸ¬ê°€ ì´ë¯¸ ìˆìœ¼ë©´ ì¤‘ë³µ ì¶”ê°€ ë°©ì§€
            if not logger.handlers:
                # ì½˜ì†” í•¸ë“¤ëŸ¬
                handler = logging.StreamHandler(sys.stdout)
                
                # êµ¬ì¡°í™”ëœ í¬ë§·í„° ë˜ëŠ” ì¼ë°˜ í¬ë§·í„°
                if settings.ENABLE_PERFORMANCE_LOGGING:
                    formatter = StructuredFormatter()
                else:
                    formatter = logging.Formatter(
                        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
                        datefmt='%Y-%m-%d %H:%M:%S'
                    )
                
                handler.setFormatter(formatter)
                logger.addHandler(handler)
            
            cls._loggers[name] = logger
        
        return cls._loggers[name]

def setup_logger(name: str, level: int = logging.INFO) -> logging.Logger:
    """í¸ì˜ í•¨ìˆ˜"""
    return PhoenixLogger.get_logger(name, level)

def log_error_with_traceback(logger: logging.Logger, error: Exception, context: str = ""):
    """ì—ëŸ¬ì™€ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ë¥¼ í•¨ê»˜ ë¡œê¹…"""
    import traceback
    
    error_msg = f"{context}: {str(error)}" if context else str(error)
    
    extra_data = {
        'error_type': type(error).__name__,
        'context': context,
        'traceback': traceback.format_exc()
    }
    
    # êµ¬ì¡°í™”ëœ ë¡œê¹…ì´ í™œì„±í™”ëœ ê²½ìš°
    if settings.ENABLE_PERFORMANCE_LOGGING:
        logger.error(error_msg, extra={'extra_data': extra_data})
    else:
        logger.error(error_msg)
        logger.error(f"ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}")

def log_performance(func):
    """ì„±ëŠ¥ ë¡œê¹… ë°ì½”ë ˆì´í„°"""
    @wraps(func)
    async def async_wrapper(*args, **kwargs):
        if not settings.ENABLE_PERFORMANCE_LOGGING:
            return await func(*args, **kwargs)
        
        logger = setup_logger(f'Performance.{func.__module__}')
        start_time = time.time()
        
        try:
            result = await func(*args, **kwargs)
            execution_time = (time.time() - start_time) * 1000
            
            if execution_time > settings.SLOW_QUERY_THRESHOLD_MS:
                logger.warning(f"Slow operation: {func.__name__} took {execution_time:.2f}ms", 
                             extra={'extra_data': {
                                 'function': func.__name__,
                                 'execution_time_ms': execution_time,
                                 'slow_query': True
                             }})
            
            return result
        except Exception as e:
            execution_time = (time.time() - start_time) * 1000
            log_error_with_traceback(logger, e, f"Performance tracking for {func.__name__}")
            raise
    
    @wraps(func)
    def sync_wrapper(*args, **kwargs):
        if not settings.ENABLE_PERFORMANCE_LOGGING:
            return func(*args, **kwargs)
        
        logger = setup_logger(f'Performance.{func.__module__}')
        start_time = time.time()
        
        try:
            result = func(*args, **kwargs)
            execution_time = (time.time() - start_time) * 1000
            
            if execution_time > settings.SLOW_QUERY_THRESHOLD_MS:
                logger.warning(f"Slow operation: {func.__name__} took {execution_time:.2f}ms")
            
            return result
        except Exception as e:
            execution_time = (time.time() - start_time) * 1000
            log_error_with_traceback(logger, e, f"Performance tracking for {func.__name__}")
            raise
    
    return async_wrapper if hasattr(func, '__await__') else sync_wrapper
```

---

## ğŸ”„ **3. ê³ ê¸‰ Redis ê´€ë¦¬ì (utils/redis_manager.py)**

```python
"""
Phoenix 95 - ê³ ê¸‰ Redis ì—°ê²° ê´€ë¦¬
Critical Issue #1 ì™„ì „ í•´ê²°: ì—°ê²° í’€ + ì¬ì—°ê²° + í—¬ìŠ¤ì²´í¬
"""

import aioredis
import json
import asyncio
from typing import Optional, Dict, Any, Union
from utils.logger import setup_logger, log_error_with_traceback, log_performance
from config.settings import settings

class RedisManager:
    """Redis ì—°ê²° ê´€ë¦¬ (ì™„ì „ ë³´ì•ˆ + ì„±ëŠ¥ ìµœì í™”)"""
    
    _instance: Optional['RedisManager'] = None
    _redis_pool: Optional[aioredis.ConnectionPool] = None
    _redis: Optional[aioredis.Redis] = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        if not hasattr(self, 'initialized'):
            self.logger = setup_logger('Phoenix95.Redis')
            self.max_retries = 3
            self.retry_delay = 1  # ì´ˆ
            self.connection_timeout = 10
            self.initialized = True
    
    async def get_redis(self) -> aioredis.Redis:
        """Redis í´ë¼ì´ì–¸íŠ¸ ë°˜í™˜ (ì—°ê²° í’€ ì‚¬ìš©)"""
        try:
            if self._redis is None or self._redis_pool is None:
                await self._create_connection_pool()
            
            # ì—°ê²° ìƒíƒœ í™•ì¸
            if not await self._is_connection_healthy():
                self.logger.warning("Redis ì—°ê²° ë¶ˆëŸ‰, ì¬ì—°ê²° ì‹œë„...")
                await self._reconnect()
            
            return self._redis
            
        except Exception as e:
            self.logger.error(f"Redis ì—°ê²° ì‹¤íŒ¨: {str(e)}")
            raise
    
    async def _create_connection_pool(self):
        """ì—°ê²° í’€ ìƒì„±"""
        try:
            self.logger.info("Redis ì—°ê²° í’€ ìƒì„± ì¤‘...")
            
            self._redis_pool = aioredis.ConnectionPool.from_url(
                settings.redis_url,
                max_connections=settings.REDIS_MAX_CONNECTIONS,
                retry_on_timeout=settings.REDIS_RETRY_ON_TIMEOUT,
                socket_keepalive=settings.REDIS_SOCKET_KEEPALIVE,
                socket_connect_timeout=self.connection_timeout,
                encoding="utf-8",
                decode_responses=True
            )
            
            self._redis = aioredis.Redis(connection_pool=self._redis_pool)
            
            # ì—°ê²° í…ŒìŠ¤íŠ¸
            await self._redis.ping()
            self.logger.info(f"Redis ì—°ê²° í’€ ìƒì„± ì™„ë£Œ (ìµœëŒ€ ì—°ê²°: {settings.REDIS_MAX_CONNECTIONS})")
            
        except Exception as e:
            self.logger.error(f"Redis ì—°ê²° í’€ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise
    
    async def _is_connection_healthy(self) -> bool:
        """ì—°ê²° ìƒíƒœ í™•ì¸"""
        try:
            if self._redis is None:
                return False
            
            # ê°„ë‹¨í•œ ping í…ŒìŠ¤íŠ¸
            await asyncio.wait_for(self._redis.ping(), timeout=2)
            return True
        except Exception:
            return False
    
    async def _reconnect(self):
        """ì¬ì—°ê²° ë¡œì§"""
        for attempt in range(self.max_retries):
            try:
                self.logger.info(f"Redis ì¬ì—°ê²° ì‹œë„ {attempt + 1}/{self.max_retries}")
                
                # ê¸°ì¡´ ì—°ê²° ì •ë¦¬
                if self._redis:
                    await self._redis.close()
                if self._redis_pool:
                    await self._redis_pool.disconnect()
                
                # ìƒˆ ì—°ê²° ìƒì„±
                await self._create_connection_pool()
                return
                
            except Exception as e:
                self.logger.error(f"ì¬ì—°ê²° ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}): {str(e)}")
                if attempt < self.max_retries - 1:
                    await asyncio.sleep(self.retry_delay * (2 ** attempt))  # ì§€ìˆ˜ ë°±ì˜¤í”„
                else:
                    raise
    
    @log_performance
    async def set_json(self, key: str, value: Dict[str, Any], expire: int = 300):
        """JSON ë°ì´í„°ë¥¼ Redisì— ì €ì¥ (ì„±ëŠ¥ ìµœì í™”)"""
        redis_client = await self.get_redis()
        
        # í‚¤ ë„¤ì´ë° ì»¨ë²¤ì…˜ ì ìš©
        prefixed_key = self._apply_key_naming(key)
        
        try:
            json_str = json.dumps(value, ensure_ascii=False, separators=(',', ':'))
            await redis_client.setex(prefixed_key, expire, json_str)
        except Exception as e:
            log_error_with_traceback(self.logger, e, f"Redis SET ì‹¤íŒ¨: {prefixed_key}")
            raise
    
    @log_performance
    async def get_json(self, key: str) -> Optional[Dict[str, Any]]:
        """Redisì—ì„œ JSON ë°ì´í„° ì¡°íšŒ"""
        redis_client = await self.get_redis()
        prefixed_key = self._apply_key_naming(key)
        
        try:
            json_str = await redis_client.get(prefixed_key)
            if json_str:
                return json.loads(json_str)
            return None
        except Exception as e:
            log_error_with_traceback(self.logger, e, f"Redis GET ì‹¤íŒ¨: {prefixed_key}")
            return None
    
    async def hset_json(self, name: str, key: str, value: Dict[str, Any]):
        """Hashì— JSON ë°ì´í„° ì €ì¥"""
        redis_client = await self.get_redis()
        prefixed_name = self._apply_key_naming(name)
        
        try:
            json_str = json.dumps(value, ensure_ascii=False, separators=(',', ':'))
            await redis_client.hset(prefixed_name, key, json_str)
        except Exception as e:
            log_error_with_traceback(self.logger, e, f"Redis HSET ì‹¤íŒ¨: {prefixed_name}.{key}")
            raise
    
    async def hget_json(self, name: str, key: str) -> Optional[Dict[str, Any]]:
        """Hashì—ì„œ JSON ë°ì´í„° ì¡°íšŒ"""
        redis_client = await self.get_redis()
        prefixed_name = self._apply_key_naming(name)
        
        try:
            json_str = await redis_client.hget(prefixed_name, key)
            if json_str:
                return json.loads(json_str)
            return None
        except Exception as e:
            log_error_with_traceback(self.logger, e, f"Redis HGET ì‹¤íŒ¨: {prefixed_name}.{key}")
            return None
    
    async def hgetall_json(self, name: str) -> Dict[str, Dict[str, Any]]:
        """Hashì˜ ëª¨ë“  JSON ë°ì´í„° ì¡°íšŒ"""
        redis_client = await self.get_redis()
        prefixed_name = self._apply_key_naming(name)
        
        try:
            hash_data = await redis_client.hgetall(prefixed_name)
            result = {}
            
            for key, json_str in hash_data.items():
                try:
                    result[key] = json.loads(json_str)
                except json.JSONDecodeError:
                    self.logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨: {prefixed_name}.{key}")
                    continue
            
            return result
        except Exception as e:
            log_error_with_traceback(self.logger, e, f"Redis HGETALL ì‹¤íŒ¨: {prefixed_name}")
            return {}
    
    async def hdel(self, name: str, key: str):
        """Hashì—ì„œ í‚¤ ì‚­ì œ"""
        redis_client = await self.get_redis()
        prefixed_name = self._apply_key_naming(name)
        await redis_client.hdel(prefixed_name, key)
    
    async def delete(self, key: str):
        """í‚¤ ì‚­ì œ"""
        redis_client = await self.get_redis()
        prefixed_key = self._apply_key_naming(key)
        await redis_client.delete(prefixed_key)
    
    async def exists(self, key: str) -> bool:
        """í‚¤ ì¡´ì¬ í™•ì¸"""
        redis_client = await self.get_redis()
        prefixed_key = self._apply_key_naming(key)
        return bool(await redis_client.exists(prefixed_key))
    
    async def expire(self, key: str, seconds: int):
        """í‚¤ ë§Œë£Œ ì‹œê°„ ì„¤ì •"""
        redis_client = await self.get_redis()
        prefixed_key = self._apply_key_naming(key)
        await redis_client.expire(prefixed_key, seconds)
    
    async def flushdb(self):
        """í˜„ì¬ DBì˜ ëª¨ë“  í‚¤ ì‚­ì œ"""
        redis_client = await self.get_redis()
        await redis_client.flushdb()
        self.logger.warning("Redis ë°ì´í„°ë² ì´ìŠ¤ í”ŒëŸ¬ì‹œ ì™„ë£Œ")
    
    def _apply_key_naming(self, key: str) -> str:
        """í‚¤ ë„¤ì´ë° ì»¨ë²¤ì…˜ ì ìš©"""
        # phoenix95: ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì ‘ë‘ì–´ ì¶”ê°€
        if not key.startswith('phoenix95:'):
            return f'phoenix95:{key}'
        return key
    
    async def get_memory_usage(self) -> Dict[str, Any]:
        """Redis ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¡°íšŒ"""
        try:
            redis_client = await self.get_redis()
            memory_info = await redis_client.memory_usage()
            return {
                'used_memory': memory_info.get('used_memory', 0),
                'used_memory_human': memory_info.get('used_memory_human', '0B'),
                'maxmemory': memory_info.get('maxmemory', 0),
                'memory_usage_percentage': memory_info.get('used_memory', 0) / max(memory_info.get('maxmemory', 1), 1) * 100
            }
        except Exception as e:
            log_error_with_traceback(self.logger, e, "Redis ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¡°íšŒ")
            return {}
    
    async def cleanup_expired_keys(self):
        """ë§Œë£Œëœ í‚¤ ì •ë¦¬"""
        try:
            redis_client = await self.get_redis()
            
            # phoenix95 ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì˜ í‚¤ë“¤ë§Œ ì¡°íšŒ
            keys = await redis_client.keys('phoenix95:*')
            expired_count = 0
            
            for key in keys:
                ttl = await redis_client.ttl(key)
                if ttl == -1:  # TTLì´ ì„¤ì •ë˜ì§€ ì•Šì€ í‚¤
                    # ê¸°ë³¸ TTL ì„¤ì • (24ì‹œê°„)
                    await redis_client.expire(key, 86400)
                elif ttl == -2:  # ë§Œë£Œëœ í‚¤
                    expired_count += 1
            
            if expired_count > 0:
                self.logger.info(f"ë§Œë£Œëœ í‚¤ ì •ë¦¬ ì™„ë£Œ: {expired_count}ê°œ")
                
        except Exception as e:
            log_error_with_traceback(self.logger, e, "í‚¤ ì •ë¦¬ ì‘ì—…")
    
    async def close(self):
        """Redis ì—°ê²° ì¢…ë£Œ"""
        if self._redis:
            await self._redis.close()
        if self._redis_pool:
            await self._redis_pool.disconnect()
        self.logger.info("Redis ì—°ê²° ì¢…ë£Œ")

# ì „ì—­ Redis ë§¤ë‹ˆì €
redis_manager = RedisManager()
```

---

## ğŸ’¾ **4. ì™„ì „ ì•ˆì „ DB ê´€ë¦¬ì (utils/database.py)**

```python
"""
Phoenix 95 - ì™„ì „ ì•ˆì „ ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬
Critical Issue #2 ì™„ì „ í•´ê²°: íŠ¸ëœì­ì…˜ ì•ˆì „ì„± + Deadlock ì²˜ë¦¬
"""

import asyncpg
import asyncio
from typing import Optional, List, Dict, Any, Union
from contextlib import asynccontextmanager
from utils.logger import setup_logger, log_error_with_traceback, log_performance
from config.settings import settings

class DatabaseManager:
    """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ê´€ë¦¬ (ì™„ì „ ì•ˆì „ + ì„±ëŠ¥ ìµœì í™”)"""
    
    _instance: Optional['DatabaseManager'] = None
    _connection_pool: Optional[asyncpg.Pool] = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        if not hasattr(self, 'initialized'):
            self.logger = setup_logger('Phoenix95.Database')
            self.max_retries = 3
            self.deadlock_retry_count = 3
            self.deadlock_retry_delay = 0.1  # 100ms
            self.initialized = True
    
    async def get_connection_pool(self) -> asyncpg.Pool:
        """ì—°ê²° í’€ ë°˜í™˜ (ìë™ ìƒì„±)"""
        if self._connection_pool is None:
            await self._create_connection_pool()
        return self._connection_pool
    
    async def _create_connection_pool(self):
        """ì—°ê²° í’€ ìƒì„±"""
        try:
            self.logger.info("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ ìƒì„± ì¤‘...")
            
            self._connection_pool = await asyncpg.create_pool(
                settings.database_url,
                min_size=5,
                max_size=20,
                command_timeout=30,
                server_settings={
                    'application_name': 'phoenix95',
                    'timezone': 'UTC'
                }
            )
            
            # ì—°ê²° í…ŒìŠ¤íŠ¸
            async with self._connection_pool.acquire() as conn:
                await conn.fetchval("SELECT 1")
            
            self.logger.info("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ ìƒì„± ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise
    
    @asynccontextmanager
    async def get_connection(self):
        """ì—°ê²° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
        pool = await self.get_connection_pool()
        
        async with pool.acquire() as connection:
            try:
                yield connection
            except Exception as e:
                # ì—°ê²° ìƒíƒœ ë³µêµ¬
                if connection.is_closed():
                    self.logger.warning("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì´ ë‹«í˜”ìŠµë‹ˆë‹¤. í’€ì„ ì¬ìƒì„±í•©ë‹ˆë‹¤.")
                    await self._recreate_pool()
                raise e
    
    async def _recreate_pool(self):
        """ì—°ê²° í’€ ì¬ìƒì„±"""
        if self._connection_pool:
            await self._connection_pool.close()
            self._connection_pool = None
        await self._create_connection_pool()
    
    @log_performance
    async def execute_with_transaction(self, queries: List[str], params_list: List[List] = None) -> List[Any]:
        """íŠ¸ëœì­ì…˜ìœ¼ë¡œ ì—¬ëŸ¬ ì¿¼ë¦¬ ì‹¤í–‰ (ì™„ì „ ì•ˆì „)"""
        if params_list is None:
            params_list = [[] for _ in queries]
        
        for attempt in range(self.deadlock_retry_count):
            try:
                async with self.get_connection() as conn:
                    async with conn.transaction():
                        results = []
                        
                        for i, query in enumerate(queries):
                            params = params_list[i] if i < len(params_list) else []
                            
                            try:
                                if params:
                                    result = await conn.fetchval(query, *params)
                                else:
                                    result = await conn.fetchval(query)
                                results.append(result)
                            except Exception as e:
                                self.logger.error(f"ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨ (ì¸ë±ìŠ¤: {i}): {query[:100]}...")
                                raise
                        
                        return results
                        
            except asyncpg.DeadlockDetectedError as e:
                if attempt < self.deadlock_retry_count - 1:
                    delay = self.deadlock_retry_delay * (2 ** attempt)  # ì§€ìˆ˜ ë°±ì˜¤í”„
                    self.logger.warning(f"Deadlock ê°ì§€, {delay:.2f}ì´ˆ í›„ ì¬ì‹œë„ (ì‹œë„ {attempt + 1}/{self.deadlock_retry_count})")
                    await asyncio.sleep(delay)
                    continue
                else:
                    log_error_with_traceback(self.logger, e, "Deadlock ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼")
                    raise
            except Exception as e:
                log_error_with_traceback(self.logger, e, "íŠ¸ëœì­ì…˜ ì‹¤í–‰")
                raise
        
        # ì´ ì§€ì ì— ë„ë‹¬í•´ì„œëŠ” ì•ˆ ë¨
        raise RuntimeError("íŠ¸ëœì­ì…˜ ì‹¤í–‰ ì˜ˆìƒì¹˜ ëª»í•œ ì¢…ë£Œ")
    
    @log_performance
    async def execute_query(self, query: str, *params) -> Any:
        """ë‹¨ì¼ ì¿¼ë¦¬ ì‹¤í–‰"""
        async with self.get_connection() as conn:
            try:
                return await conn.fetchval(query, *params)
            except Exception as e:
                self.logger.error(f"ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {query[:100]}...")
                log_error_with_traceback(self.logger, e, "ë‹¨ì¼ ì¿¼ë¦¬ ì‹¤í–‰")
                raise
    
    @log_performance
    async def fetch_one(self, query: str, *params) -> Optional[Dict[str, Any]]:
        """ë‹¨ì¼ ë ˆì½”ë“œ ì¡°íšŒ"""
        async with self.get_connection() as conn:
            try:
                record = await conn.fetchrow(query, *params)
                return dict(record) if record else None
            except Exception as e:
                log_error_with_traceback(self.logger, e, "ë‹¨ì¼ ë ˆì½”ë“œ ì¡°íšŒ")
                raise
    
    @log_performance
    async def fetch_all(self, query: str, *params) -> List[Dict[str, Any]]:
        """ë‹¤ì¤‘ ë ˆì½”ë“œ ì¡°íšŒ"""
        async with self.get_connection() as conn:
            try:
                records = await conn.fetch(query, *params)
                return [dict(record) for record in records]
            except Exception as e:
                log_error_with_traceback(self.logger, e, "ë‹¤ì¤‘ ë ˆì½”ë“œ ì¡°íšŒ")
                raise
    
    @asynccontextmanager
    async def transaction(self):
        """íŠ¸ëœì­ì…˜ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € (ì¤‘ì²© ì§€ì›)"""
        async with self.get_connection() as conn:
            transaction = conn.transaction()
            await transaction.start()
            
            try:
                yield conn
                await transaction.commit()
            except Exception as e:
                await transaction.rollback()
                log_error_with_traceback(self.logger, e, "íŠ¸ëœì­ì…˜ ë¡¤ë°±")
                raise
    
    async def execute_script(self, script: str):
        """SQL ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰"""
        async with self.get_connection() as conn:
            try:
                await conn.execute(script)
                self.logger.info("SQL ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì™„ë£Œ")
            except Exception as e:
                log_error_with_traceback(self.logger, e, "SQL ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰")
                raise
    
    async def get_database_stats(self) -> Dict[str, Any]:
        """ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì¡°íšŒ"""
        try:
            async with self.get_connection() as conn:
                stats = await conn.fetchrow("""
                    SELECT 
                        pg_size_pretty(pg_database_size(current_database())) as db_size,
                        current_database() as db_name,
                        version() as pg_version,
                        (SELECT count(*) FROM pg_stat_activity WHERE state = 'active') as active_connections,
                        (SELECT setting FROM pg_settings WHERE name = 'max_connections') as max_connections
                """)
                
                # í…Œì´ë¸”ë³„ í¬ê¸° ì •ë³´
                table_sizes = await conn.fetch("""
                    SELECT 
                        schemaname,
                        tablename,
                        pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size
                    FROM pg_tables 
                    WHERE schemaname = 'public'
                    ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC
                    LIMIT 10
                """)
                
                return {
                    'database_info': dict(stats),
                    'table_sizes': [dict(table) for table in table_sizes]
                }
        except Exception as e:
            log_error_with_traceback(self.logger, e, "ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì¡°íšŒ")
            return {}
    
    async def cleanup_old_data(self):
        """ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬"""
        try:
            async with self.transaction() as conn:
                # 30ì¼ ì´ìƒëœ ì„±ëŠ¥ ë¡œê·¸ ì‚­ì œ
                deleted_logs = await conn.fetchval("""
                    DELETE FROM performance_logs 
                    WHERE created_at < NOW() - INTERVAL '30 days'
                    RETURNING COUNT(*)
                """)
                
                # 7ì¼ ì´ìƒëœ í™•ì¸ëœ ì•Œë¦¼ ì‚­ì œ
                deleted_alerts = await conn.fetchval("""
                    DELETE FROM alerts 
                    WHERE acknowledged = TRUE 
                    AND acknowledged_at < NOW() - INTERVAL '7 days'
                    RETURNING COUNT(*)
                """)
                
                # 90ì¼ ì´ìƒëœ 1ë¶„ë´‰ ì‹œì¥ ë°ì´í„° ì‚­ì œ
                deleted_market_data = await conn.fetchval("""
                    DELETE FROM market_data 
                    WHERE timeframe = '1m' 
                    AND timestamp < NOW() - INTERVAL '90 days'
                    RETURNING COUNT(*)
                """)
                
                self.logger.info(f"ë°ì´í„° ì •ë¦¬ ì™„ë£Œ: ë¡œê·¸ {deleted_logs or 0}ê°œ, ì•Œë¦¼ {deleted_alerts or 0}ê°œ, ì‹œì¥ë°ì´í„° {deleted_market_data or 0}ê°œ")
                
        except Exception as e:
            log_error_with_traceback(self.logger, e, "ë°ì´í„° ì •ë¦¬ ì‘ì—…")
    
    async def health_check(self) -> Dict[str, Any]:
        """í—¬ìŠ¤ì²´í¬"""
        try:
            start_time = asyncio.get_event_loop().time()
            
            async with self.get_connection() as conn:
                # ê¸°ë³¸ ì—°ê²° í…ŒìŠ¤íŠ¸
                await conn.fetchval("SELECT 1")
                
                # ì‘ë‹µ ì‹œê°„ ì¸¡ì •
                response_time = (asyncio.get_event_loop().time() - start_time) * 1000
                
                # ì—°ê²° í’€ ìƒíƒœ
                pool = await self.get_connection_pool()
                
                return {
                    'status': 'healthy',
                    'response_time_ms': round(response_time, 2),
                    'pool_size': pool.get_size(),
                    'pool_max_size': pool.get_max_size(),
                    'pool_min_size': pool.get_min_size()
                }
                
        except Exception as e:
            log_error_with_traceback(self.logger, e, "ë°ì´í„°ë² ì´ìŠ¤ í—¬ìŠ¤ì²´í¬")
            return {
                'status': 'unhealthy',
                'error': str(e)
            }
    
    async def close_connection_pool(self):
        """ì—°ê²° í’€ ì¢…ë£Œ"""
        if self._connection_pool:
            await self._connection_pool.close()
            self._connection_pool = None
            self.logger.info("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ ì¢…ë£Œ")

# ì „ì—­ ë°ì´í„°ë² ì´ìŠ¤ ë§¤ë‹ˆì €
db_manager = DatabaseManager()
```

---

## ğŸ“Š **5. ì™„ì „ Risk Calculator (utils/risk_calculator.py)**

```python
"""
Phoenix 95 - ì™„ì „í•œ ë¦¬ìŠ¤í¬ ê³„ì‚° ì‹œìŠ¤í…œ
High Priority Issue #17 ì™„ì „ í•´ê²°: Kelly Criterion ì•ˆì „ ë²”ìœ„ + ì‹œì¥ ë³€ë™ì„±
"""

import math
import numpy as np
from typing import Dict, Any, List, Optional
from decimal import Decimal, ROUND_DOWN
from config.settings import settings
from utils.logger import setup_logger

class AdvancedRiskCalculator:
    """ê³ ê¸‰ ë¦¬ìŠ¤í¬ ê³„ì‚°ê¸° - í—¤ì§€í€ë“œê¸‰ í’ˆì§ˆ"""
    
    def __init__(self):
        self.logger = setup_logger('Phoenix95.RiskCalculator')
        
        # ë¦¬ìŠ¤í¬ ìƒìˆ˜
        self.MAX_POSITION_RISK = 0.05  # ë‹¨ì¼ í¬ì§€ì…˜ ìµœëŒ€ ë¦¬ìŠ¤í¬ 5%
        self.MAX_PORTFOLIO_RISK = 0.15  # í¬íŠ¸í´ë¦¬ì˜¤ ìµœëŒ€ ë¦¬ìŠ¤í¬ 15%
        self.VOLATILITY_MULTIPLIER = 1.5  # ë³€ë™ì„± ì¡°ì • ë°°ìˆ˜
        
    def calculate_signal_risk(self, phoenix_score: float, signal_data: Dict[str, Any]) -> float:
        """ì‹ í˜¸ ë ˆë²¨ ë¦¬ìŠ¤í¬ ì¡°ì • (ê³ ê¸‰ ë²„ì „)"""
        try:
            rsi = signal_data.get('rsi', 50)
            volume = signal_data.get('volume', 0)
            price = float(signal_data.get('price', 0))
            
            # ê¸°ë³¸ ë¦¬ìŠ¤í¬ ì¡°ì •
            risk_adjusted = phoenix_score
            
            # 1. RSI ê¸°ë°˜ ì‹œì¥ ê³¼ì—´ë„ ì¡°ì •
            rsi_adjustment = self._calculate_rsi_adjustment(rsi)
            risk_adjusted *= rsi_adjustment
            
            # 2. ê±°ë˜ëŸ‰ ê¸°ë°˜ ìœ ë™ì„± ì¡°ì •
            volume_adjustment = self._calculate_volume_adjustment(volume)
            risk_adjusted *= volume_adjustment
            
            # 3. ê°€ê²© ë ˆë²¨ ê¸°ë°˜ ì¡°ì •
            price_adjustment = self._calculate_price_adjustment(price)
            risk_adjusted *= price_adjustment
            
            # 4. ì‹œì¥ ë³€ë™ì„± ê¸°ë°˜ ì¡°ì •
            volatility_adjustment = self._calculate_volatility_adjustment(signal_data)
            risk_adjusted *= volatility_adjustment
            
            # ìµœì¢… ë²”ìœ„ ì œí•œ
            return max(0.0, min(risk_adjusted, 1.0))
            
        except Exception as e:
            self.logger.error(f"ì‹ í˜¸ ë¦¬ìŠ¤í¬ ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
            return 0.0
    
    def _calculate_rsi_adjustment(self, rsi: float) -> float:
        """RSI ê¸°ë°˜ ì¡°ì •"""
        if rsi < 10 or rsi > 90:  # ê·¹ë‹¨ì  ê³¼ë§¤ë„/ê³¼ë§¤ìˆ˜
            return 0.5  # 50% ê°ì†Œ
        elif rsi < 20 or rsi > 80:  # ê³¼ë§¤ë„/ê³¼ë§¤ìˆ˜
            return 0.7  # 30% ê°ì†Œ
        elif 30 <= rsi <= 70:  # ì •ìƒ ë²”ìœ„
            return 1.1  # 10% ì¦ê°€
        else:  # ì£¼ì˜ ë²”ìœ„
            return 0.9  # 10% ê°ì†Œ
    
    def _calculate_volume_adjustment(self, volume: int) -> float:
        """ê±°ë˜ëŸ‰ ê¸°ë°˜ ìœ ë™ì„± ì¡°ì •"""
        if volume <= 0:
            return 0.8  # ê±°ë˜ëŸ‰ ì •ë³´ ì—†ìŒ
        
        # ì •ê·œí™”ëœ ê±°ë˜ëŸ‰ (ë°±ë§Œ ê¸°ì¤€)
        volume_millions = volume / 1_000_000
        
        if volume_millions > 100:  # ë§¤ìš° ë†’ì€ ê±°ë˜ëŸ‰
            return 1.2
        elif volume_millions > 10:  # ë†’ì€ ê±°ë˜ëŸ‰
            return 1.1
        elif volume_millions > 1:  # ì •ìƒ ê±°ë˜ëŸ‰
            return 1.0
        else:  # ë‚®ì€ ê±°ë˜ëŸ‰
            return 0.85
    
    def _calculate_price_adjustment(self, price: float) -> float:
        """ê°€ê²© ë ˆë²¨ ê¸°ë°˜ ì¡°ì •"""
        if price <= 0:
            return 0.0
        
        # ì‹¬ë¦¬ì  ê°€ê²©ëŒ€ í™•ì¸
        price_str = str(int(price))
        
        # ë¼ìš´ë“œ ë„˜ë²„ (10000, 50000 ë“±) ê·¼ì²˜ì—ì„œëŠ” ì €í•­/ì§€ì§€ ê°•í•¨
        if price_str.endswith('0000') or price_str.endswith('5000'):
            return 0.9  # 10% ê°ì†Œ
        elif price_str.endswith('000') or price_str.endswith('500'):
            return 0.95  # 5% ê°ì†Œ
        else:
            return 1.0
    
    def _calculate_volatility_adjustment(self, signal_data: Dict[str, Any]) -> float:
        """ì‹œì¥ ë³€ë™ì„± ê¸°ë°˜ ì¡°ì •"""
        try:
            # MACD ê¸°ë°˜ ëª¨ë©˜í…€ ë³€ë™ì„±
            macd = abs(float(signal_data.get('macd', 0)))
            
            if macd > 1000:  # ë§¤ìš° ë†’ì€ ë³€ë™ì„±
                return 0.7
            elif macd > 500:  # ë†’ì€ ë³€ë™ì„±
                return 0.8
            elif macd > 100:  # ë³´í†µ ë³€ë™ì„±
                return 0.9
            else:  # ë‚®ì€ ë³€ë™ì„±
                return 1.0
                
        except Exception:
            return 1.0
    
    def calculate_position_risk(self, position_size: float, entry_price: float, leverage: int) -> float:
        """í¬ì§€ì…˜ ë ˆë²¨ ë¦¬ìŠ¤í¬ ê³„ì‚° (ê³ ê¸‰ ë²„ì „)"""
        try:
            if position_size <= 0 or entry_price <= 0 or leverage <= 0:
                return 0.0
            
            # ë ˆë²„ë¦¬ì§€ë¥¼ ê³ ë ¤í•œ ì‹¤ì œ ë…¸ì¶œ ê¸ˆì•¡
            exposure = position_size * entry_price * leverage
            
            # ê¸°ë³¸ ë¦¬ìŠ¤í¬ ê³„ì‚°
            base_risk = position_size * settings.RISK_LIMIT
            
            # ë ˆë²„ë¦¬ì§€ ì¡°ì • (ë¹„ì„ í˜•)
            leverage_multiplier = math.log(leverage + 1) / math.log(21)  # 20ë°° ê¸°ì¤€ ì •ê·œí™”
            leveraged_risk = base_risk * leverage_multiplier
            
            # ìµœëŒ€ ë¦¬ìŠ¤í¬ ì œí•œ
            return min(leveraged_risk, self.MAX_POSITION_RISK)
            
        except Exception as e:
            self.logger.error(f"í¬ì§€ì…˜ ë¦¬ìŠ¤í¬ ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
            return self.MAX_POSITION_RISK
    
    def calculate_portfolio_risk(self, active_positions: List[Dict[str, Any]]) -> float:
        """í¬íŠ¸í´ë¦¬ì˜¤ ë ˆë²¨ ë¦¬ìŠ¤í¬ ê³„ì‚° (ìƒê´€ê´€ê³„ ê³ ë ¤)"""
        try:
            if not active_positions:
                return 0.0
            
            total_risk = 0.0
            symbol_risks = {}
            
            # ê° í¬ì§€ì…˜ì˜ ë¦¬ìŠ¤í¬ ê³„ì‚°
            for position in active_positions:
                symbol = position.get('symbol', '')
                size = position.get('size', 0)
                entry_price = position.get('entry_price', 0)
                leverage = position.get('leverage', 1)
                
                position_risk = self.calculate_position_risk(size, entry_price, leverage)
                symbol_risks[symbol] = position_risk
                total_risk += position_risk
            
            # ì•”í˜¸í™”í ìƒê´€ê´€ê³„ ì¡°ì • (ê°„ë‹¨í•œ ëª¨ë¸)
            correlation_adjustment = self._calculate_correlation_adjustment(symbol_risks)
            adjusted_risk = total_risk * correlation_adjustment
            
            return min(adjusted_risk, self.MAX_PORTFOLIO_RISK)
            
        except Exception as e:
            self.logger.error(f"í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ìŠ¤í¬ ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
            return self.MAX_PORTFOLIO_RISK
    
    def _calculate_correlation_adjustment(self, symbol_risks: Dict[str, float]) -> float:
        """ì•”í˜¸í™”í ê°„ ìƒê´€ê´€ê³„ ì¡°ì •"""
        try:
            # ë¹„íŠ¸ì½”ì¸ ê´€ë ¨ ìŒì˜ ê°œìˆ˜
            btc_pairs = sum(1 for symbol in symbol_risks.keys() if 'BTC' in symbol.upper())
            eth_pairs = sum(1 for symbol in symbol_risks.keys() if 'ETH' in symbol.upper())
            
            total_pairs = len(symbol_risks)
            
            # ìƒê´€ê´€ê³„ê°€ ë†’ì€ ìŒì´ ë§ì„ìˆ˜ë¡ ë¦¬ìŠ¤í¬ ì¦ê°€
            if btc_pairs > 1:  # BTC ê´€ë ¨ ìŒì´ ì—¬ëŸ¬ ê°œ
                correlation_factor = 1.0 + (btc_pairs - 1) * 0.1
            elif eth_pairs > 1:  # ETH ê´€ë ¨ ìŒì´ ì—¬ëŸ¬ ê°œ
                correlation_factor = 1.0 + (eth_pairs - 1) * 0.08
            else:
                correlation_factor = 1.0
            
            # ë‹¤ì–‘ì„± ë³´ë„ˆìŠ¤
            if total_pairs >= 5:
                correlation_factor *= 0.95  # 5% ê°ì†Œ
            
            return min(correlation_factor, 1.5)  # ìµœëŒ€ 50% ì¦ê°€
            
        except Exception:
            return 1.0
    
    def kelly_criterion_sizing(self, win_rate: float, avg_win: float, avg_loss: float, confidence: float) -> float:
        """Kelly Criterion í¬ì§€ì…˜ ì‚¬ì´ì§• (ì™„ì „ ì•ˆì „ ë²„ì „)"""
        try:
            # ì…ë ¥ ê²€ì¦
            if not all(isinstance(x, (int, float)) for x in [win_rate, avg_win, avg_loss, confidence]):
                self.logger.error("Kelly Criterion: ì˜ëª»ëœ ì…ë ¥ íƒ€ì…")
                return 0.0
            
            if avg_loss <= 0 or win_rate <= 0 or win_rate >= 1:
                self.logger.warning(f"Kelly Criterion: ì˜ëª»ëœ ì…ë ¥ê°’ - win_rate: {win_rate}, avg_loss: {avg_loss}")
                return 0.0
            
            # Kelly ê³µì‹: f = (bp - q) / b
            # b = avg_win / avg_loss (ë°°ë‹¹ë¥ )
            # p = win_rate (ìŠ¹ë¥ )
            # q = 1 - p (íŒ¨ìœ¨)
            
            b = avg_win / avg_loss  # ë°°ë‹¹ë¥ 
            p = win_rate           # ìŠ¹ë¥ 
            q = 1 - p             # íŒ¨ìœ¨
            
            # Kelly ë¹„ìœ¨ ê³„ì‚°
            kelly_fraction = (b * p - q) / b
            
            # ì•ˆì „ ì œí•œ ì ìš©
            kelly_fraction = max(0.0, kelly_fraction)  # ìŒìˆ˜ ë°©ì§€
            kelly_fraction = min(kelly_fraction, settings.KELLY_MAX_FRACTION)  # ìµœëŒ€ 25% ì œí•œ
            
            # ì‹ ë¢°ë„ ê¸°ë°˜ ì¶”ê°€ ì¡°ì •
            confidence_adjustment = min(confidence / settings.CONFIDENCE_THRESHOLD, 1.0)
            kelly_fraction *= confidence_adjustment
            
            # ê·¹ë³´ìˆ˜ì  ì ‘ê·¼: Kellyì˜ ì ˆë°˜ë§Œ ì‚¬ìš©
            safe_kelly = kelly_fraction * 0.5
            
            # ìµœì†Œê°’ ë³´ì¥
            return max(safe_kelly, 0.001)  # ìµœì†Œ 0.1%
            
        except Exception as e:
            self.logger.error(f"Kelly Criterion ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
            return 0.001  # ì•ˆì „í•œ ìµœì†Œê°’
    
    def calculate_stop_loss(self, entry_price: float, position_side: str, volatility: float = None) -> float:
        """ë™ì  ì†ì ˆê°€ ê³„ì‚°"""
        try:
            if entry_price <= 0:
                return 0.0
            
            # ê¸°ë³¸ ì†ì ˆ ë¹„ìœ¨
            base_stop_ratio = settings.RISK_LIMIT
            
            # ë³€ë™ì„± ê¸°ë°˜ ì¡°ì •
            if volatility and volatility > 0:
                # ë†’ì€ ë³€ë™ì„±ì—ì„œëŠ” ë” ë„“ì€ ì†ì ˆí­
                volatility_adjustment = min(volatility / 0.02, 2.0)  # ìµœëŒ€ 2ë°°
                adjusted_ratio = base_stop_ratio * volatility_adjustment
            else:
                adjusted_ratio = base_stop_ratio
            
            # ë°©í–¥ì— ë”°ë¥¸ ì†ì ˆê°€ ê³„ì‚°
            if position_side.lower() in ['buy', 'long']:
                stop_price = entry_price * (1 - adjusted_ratio)
            else:  # sell, short
                stop_price = entry_price * (1 + adjusted_ratio)
            
            return round(stop_price, 2)
            
        except Exception as e:
            self.logger.error(f"ì†ì ˆê°€ ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
            return 0.0
    
    def calculate_take_profit(self, entry_price: float, position_side: str, risk_reward_ratio: float = 2.0) -> float:
        """ë™ì  ì´ìµì‹¤í˜„ê°€ ê³„ì‚°"""
        try:
            if entry_price <= 0:
                return 0.0
            
            # ë¦¬ìŠ¤í¬ ëŒ€ë¹„ ìˆ˜ìµ ë¹„ìœ¨ ì ìš©
            profit_ratio = settings.RISK_LIMIT * risk_reward_ratio
            
            # ë°©í–¥ì— ë”°ë¥¸ ì´ìµì‹¤í˜„ê°€ ê³„ì‚°
            if position_side.lower() in ['buy', 'long']:
                target_price = entry_price * (1 + profit_ratio)
            else:  # sell, short
                target_price = entry_price * (1 - profit_ratio)
            
            return round(target_price, 2)
            
        except Exception as e:
            self.logger.error(f"ì´ìµì‹¤í˜„ê°€ ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
            return 0.0
    
    def calculate_drawdown(self, equity_curve: List[float]) -> Dict[str, float]:
        """ìµœëŒ€ ë‚™í­ ê³„ì‚°"""
        try:
            if not equity_curve or len(equity_curve) < 2:
                return {'max_drawdown': 0.0, 'current_drawdown': 0.0}
            
            equity_array = np.array(equity_curve)
            running_max = np.maximum.accumulate(equity_array)
            drawdown = (equity_array - running_max) / running_max
            
            max_drawdown = abs(np.min(drawdown))
            current_drawdown = abs(drawdown[-1])
            
            return {
                'max_drawdown': round(max_drawdown, 4),
                'current_drawdown': round(current_drawdown, 4)
            }
            
        except Exception as e:
            self.logger.error(f"ë‚™í­ ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
            return {'max_drawdown': 0.0, 'current_drawdown': 0.0}
    
    def calculate_sharpe_ratio(self, returns: List[float], risk_free_rate: float = 0.02) -> float:
        """ìƒ¤í”„ ë¹„ìœ¨ ê³„ì‚°"""
        try:
            if not returns or len(returns) < 2:
                return 0.0
            
            returns_array = np.array(returns)
            excess_returns = returns_array - risk_free_rate / 252  # ì¼ì¼ ë¬´ìœ„í—˜ ìˆ˜ìµë¥ 
            
            if np.std(excess_returns) == 0:
                return 0.0
            
            sharpe = np.mean(excess_returns) / np.std(excess_returns) * np.sqrt(252)
            return round(sharpe, 4)
            
        except Exception as e:
            self.logger.error(f"ìƒ¤í”„ ë¹„ìœ¨ ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
            return 0.0
    
    def validate_risk_limits(self, position_risk: float, portfolio_risk: float) -> Dict[str, Any]:
        """ë¦¬ìŠ¤í¬ í•œë„ ê²€ì¦"""
        validation_result = {
            'position_valid': position_risk <= self.MAX_POSITION_RISK,
            'portfolio_valid': portfolio_risk <= self.MAX_PORTFOLIO_RISK,
            'overall_valid': True,
            'warnings': [],
            'errors': []
        }
        
        # í¬ì§€ì…˜ ë¦¬ìŠ¤í¬ ê²€ì¦
        if position_risk > self.MAX_POSITION_RISK:
            validation_result['errors'].append(
                f"í¬ì§€ì…˜ ë¦¬ìŠ¤í¬ ì´ˆê³¼: {position_risk:.3f} > {self.MAX_POSITION_RISK:.3f}"
            )
            validation_result['overall_valid'] = False
        elif position_risk > self.MAX_POSITION_RISK * 0.8:
            validation_result['warnings'].append(
                f"í¬ì§€ì…˜ ë¦¬ìŠ¤í¬ ê²½ê³ : {position_risk:.3f} (í•œë„ì˜ 80% ì´ˆê³¼)"
            )
        
        # í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ìŠ¤í¬ ê²€ì¦
        if portfolio_risk > self.MAX_PORTFOLIO_RISK:
            validation_result['errors'].append(
                f"í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ìŠ¤í¬ ì´ˆê³¼: {portfolio_risk:.3f} > {self.MAX_PORTFOLIO_RISK:.3f}"
            )
            validation_result['overall_valid'] = False
        elif portfolio_risk > self.MAX_PORTFOLIO_RISK * 0.8:
            validation_result['warnings'].append(
                f"í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ìŠ¤í¬ ê²½ê³ : {portfolio_risk:.3f} (í•œë„ì˜ 80% ì´ˆê³¼)"
            )
        
        return validation_result

# ì „ì—­ ë¦¬ìŠ¤í¬ ê³„ì‚°ê¸°
risk_calculator = AdvancedRiskCalculator()

# í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ê¸°ì¡´ í´ë˜ìŠ¤
class RiskCalculator:
    """í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤"""
    
    @staticmethod
    def calculate_signal_risk(phoenix_score: float, signal_data: Dict[str, Any]) -> float:
        return risk_calculator.calculate_signal_risk(phoenix_score, signal_data)
    
    @staticmethod
    def calculate_position_risk(position_size: float, entry_price: float, leverage: int) -> float:
        return risk_calculator.calculate_position_risk(position_size, entry_price, leverage)
    
    @staticmethod
    def calculate_portfolio_risk(active_positions: List[Dict[str, Any]]) -> float:
        return risk_calculator.calculate_portfolio_risk(active_positions)
    
    @staticmethod
    def kelly_criterion_sizing(win_rate: float, avg_win: float, avg_loss: float, confidence: float) -> float:
        return risk_calculator.kelly_criterion_sizing(win_rate, avg_win, avg_loss, confidence)
```

---

## ğŸ›¡ï¸ **6. ì™„ì „í•œ Rate Limiter (utils/rate_limiter.py)**

```python
"""
Phoenix 95 - Rate Limiting ì‹œìŠ¤í…œ
Medium Priority Issue #23 ì™„ì „ í•´ê²°
"""

import time
import asyncio
from typing import Dict, Optional, Any
from collections import defaultdict, deque
from utils.logger import setup_logger
from utils.redis_manager import redis_manager
from config.settings import settings

class RateLimiter:
    """ê³ ê¸‰ Rate Limiting ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.logger = setup_logger('Phoenix95.RateLimiter')
        self.local_cache: Dict[str, deque] = defaultdict(deque)
        self.lock = asyncio.Lock()
        
    async def check_rate_limit(self, key: str, limit: int, window: int) -> Dict[str, Any]:
        """Rate limit í™•ì¸"""
        try:
            current_time = time.time()
            
            # Redisì—ì„œ í˜„ì¬ ìš”ì²­ ìˆ˜ í™•ì¸
            redis_key = f"rate_limit:{key}"
            current_requests = await redis_manager.get_json(redis_key) or []
            
            # ìœˆë„ìš° ì™¸ë¶€ì˜ ìš”ì²­ ì œê±°
            valid_requests = [req_time for req_time in current_requests 
                            if current_time - req_time < window]
            
            # ì œí•œ í™•ì¸
            if len(valid_requests) >= limit:
                return {
                    'allowed': False,
                    'requests': len(valid_requests),
                    'limit': limit,
                    'window': window,
                    'reset_time': min(valid_requests) + window
                }
            
            # ìƒˆ ìš”ì²­ ì¶”ê°€
            valid_requests.append(current_time)
            
            # Redisì— ì—…ë°ì´íŠ¸
            await redis_manager.set_json(redis_key, valid_requests, expire=window)
            
            return {
                'allowed': True,
                'requests': len(valid_requests),
                'limit': limit,
                'window': window,
                'remaining': limit - len(valid_requests)
            }
            
        except Exception as e:
            self.logger.error(f"Rate limit í™•ì¸ ì˜¤ë¥˜: {str(e)}")
            # ì˜¤ë¥˜ ì‹œ í—ˆìš© (ì•ˆì „í•œ ê¸°ë³¸ê°’)
            return {'allowed': True, 'error': str(e)}
    
    async def binance_api_rate_limit(self, endpoint: str) -> bool:
        """ë°”ì´ë‚¸ìŠ¤ API Rate Limit í™•ì¸"""
        # ë°”ì´ë‚¸ìŠ¤ API ì œí•œ: 1200 requests/minute
        result = await self.check_rate_limit(
            f"binance_api:{endpoint}",
            settings.BINANCE_RATE_LIMIT,
            60
        )
        return result['allowed']
    
    async def trading_rate_limit(self, user_id: str) -> bool:
        """ê±°ë˜ ì£¼ë¬¸ Rate Limit"""
        # ë¶„ë‹¹ ìµœëŒ€ 60ê°œ ê±°ë˜
        result = await self.check_rate_limit(
            f"trading:{user_id}",
            settings.API_RATE_LIMIT_PER_MINUTE,
            60
        )
        return result['allowed']
    
    async def daily_trade_limit(self, user_id: str) -> bool:
        """ì¼ì¼ ê±°ë˜ í•œë„ í™•ì¸"""
        result = await self.check_rate_limit(
            f"daily_trades:{user_id}",
            settings.MAX_DAILY_TRADES,
            86400  # 24ì‹œê°„
        )
        return result['allowed']

# ì „ì—­ Rate Limiter
rate_limiter = RateLimiter()
```

---

## ğŸ§  **7. ì™„ì „í•œ AI Engine (services/ai_engine.py)**

```python
"""
Phoenix 95 AI Engine - ì™„ì „ ìµœì í™” ë²„ì „
Critical Issue #7 ì™„ì „ í•´ê²°: ì„±ëŠ¥ + ìºì‹± + Materialized View
"""

import asyncio
import time
from datetime import datetime, timedelta
from typing import Dict, Any, Optional
from decimal import Decimal

from fastapi import FastAPI, HTTPException, Depends
from pydantic import ValidationError
import uvicorn

from models.schemas import SignalData, AnalysisResult, HealthCheck
from utils.logger import setup_logger, log_error_with_traceback, log_performance
from utils.redis_manager import redis_manager
from utils.database import db_manager
from utils.risk_calculator import risk_calculator
from utils.rate_limiter import rate_limiter
from config.settings import settings

class Phoenix95Engine:
    """í—¤ì§€í€ë“œê¸‰ AI ë¶„ì„ ì—”ì§„ - ì™„ì „ ìµœì í™”"""
    
    def __init__(self):
        self.confidence_threshold = settings.CONFIDENCE_THRESHOLD
        self.risk_limit = settings.RISK_LIMIT
        self.logger = setup_logger('Phoenix95.Engine')
        
        # ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ ìºì‹œ
        self._historical_cache = None
        self._cache_timestamp = 0
        self._cache_ttl = 1800  # 30ë¶„
        
    @log_performance
    async def analyze_signal(self, signal_data: Dict[str, Any], request_id: str = None) -> AnalysisResult:
        """Phoenix 95 í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ - ì™„ì „ ìµœì í™”"""
        
        try:
            # Rate limiting í™•ì¸
            if not await rate_limiter.check_rate_limit("ai_analysis", 100, 60):
                return AnalysisResult(
                    action="ERROR",
                    reason="Rate limit exceeded"
                )
            
            # 1. ì…ë ¥ ë°ì´í„° ê²€ì¦
            try:
                signal = SignalData(**signal_data)
            except ValidationError as e:
                return AnalysisResult(
                    action="ERROR", 
                    reason=f"ì…ë ¥ ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨: {str(e)}"
                )
            
            # 2. ì¤‘ë³µ ìš”ì²­ í™•ì¸ (Idempotency)
            if request_id:
                cached_result = await redis_manager.get_json(f"analysis_result:{request_id}")
                if cached_result:
                    self.logger.info(f"ìºì‹œëœ ë¶„ì„ ê²°ê³¼ ë°˜í™˜: {request_id}")
                    return AnalysisResult(**cached_result)
            
            # 3. ê¸°ìˆ ì  ë¶„ì„ (30% ê°€ì¤‘ì¹˜)
            technical_score = await self._technical_analysis(signal)
            
            # 4. Phoenix 95 ì•Œê³ ë¦¬ì¦˜ (50% ê°€ì¤‘ì¹˜)
            phoenix_score = await self._phoenix95_algorithm(signal)
            
            # 5. ì‹œì¥ ìƒí™© ë¶„ì„ (20% ê°€ì¤‘ì¹˜)
            market_score = await self._market_condition_analysis(signal)
            
            # 6. ì¢…í•© ì ìˆ˜ ê³„ì‚°
            final_score = (
                technical_score * 0.3 +
                phoenix_score * 0.5 +
                market_score * 0.2
            )
            
            # 7. ë¦¬ìŠ¤í¬ ì¡°ì •
            risk_adjusted = risk_calculator.calculate_signal_risk(
                final_score, 
                signal.dict()
            )
            
            # 8. ìµœì¢… íŒì •
            if risk_adjusted > self.confidence_threshold:
                # Kelly Criterionìœ¼ë¡œ í¬ì§€ì…˜ ì‚¬ì´ì§•
                historical_data = await self._get_historical_performance()
                position_size = risk_calculator.kelly_criterion_sizing(
                    historical_data['win_rate'],
                    historical_data['avg_win'],
                    historical_data['avg_loss'],
                    risk_adjusted
                )
                
                # ë™ì  ì†ì ˆ/ìµì ˆê°€ ê³„ì‚°
                stop_loss = risk_calculator.calculate_stop_loss(
                    float(signal.price), 
                    signal.action
                )
                take_profit = risk_calculator.calculate_take_profit(
                    float(signal.price), 
                    signal.action
                )
                
                result = AnalysisResult(
                    action="EXECUTE",
                    confidence=risk_adjusted,
                    phoenix95_score=final_score,
                    position_size=position_size,
                    stop_loss=Decimal(str(stop_loss)),
                    take_profit=Decimal(str(take_profit)),
                    leverage=settings.MAX_LEVERAGE,
                    reasoning=f"Tech:{technical_score:.3f} Phoenix:{phoenix_score:.3f} Market:{market_score:.3f} Final:{risk_adjusted:.3f}",
                    timestamp=datetime.now()
                )
                
                # ê²°ê³¼ ìºì‹±
                if request_id:
                    await redis_manager.set_json(
                        f"analysis_result:{request_id}", 
                        result.dict(),
                        expire=300
                    )
                
                # ë¶„ì„ í†µê³„ ì—…ë°ì´íŠ¸
                await self._update_analysis_stats(signal, result)
                
                self.logger.info(f"ì‹ í˜¸ ìŠ¹ì¸: {signal.symbol} - ìµœì¢…ì ìˆ˜: {risk_adjusted:.3f}")
                return result
                
            self.logger.info(f"ì‹ í˜¸ ê±°ë¶€: {signal.symbol} - ë‚®ì€ ì ìˆ˜: {risk_adjusted:.3f}")
            return AnalysisResult(
                action="HOLD", 
                confidence=risk_adjusted,
                phoenix95_score=final_score,
                reasoning=f"ë‚®ì€ ì‹ ë¢°ë„: {risk_adjusted:.3f} < {self.confidence_threshold}",
                timestamp=datetime.now()
            )
            
        except Exception as e:
            log_error_with_traceback(self.logger, e, "ì‹ í˜¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜")
            return AnalysisResult(action="ERROR", reason=str(e), timestamp=datetime.now())
    
    async def _technical_analysis(self, signal: SignalData) -> float:
        """ê¸°ìˆ ì  ë¶„ì„ (í–¥ìƒëœ ë²„ì „)"""
        confidence = signal.confidence
        rsi = signal.rsi or 50
        macd = float(signal.macd) if signal.macd else 0
        
        # ê¸°ë³¸ ê¸°ìˆ ì  ì ìˆ˜
        technical_score = confidence
        
        # RSI ë¶„ì„ (ì˜¤ì‹¤ë ˆì´í„°)
        rsi_factor = self._analyze_rsi(rsi)
        technical_score *= rsi_factor
        
        # MACD ë¶„ì„ (ëª¨ë©˜í…€)
        macd_factor = self._analyze_macd(macd)
        technical_score *= macd_factor
        
        # ê°€ê²© ì•¡ì…˜ ë¶„ì„
        price_action_factor = await self._analyze_price_action(signal)
        technical_score *= price_action_factor
        
        return min(technical_score, 1.0)
    
    def _analyze_rsi(self, rsi: float) -> float:
        """RSI ì‹¬í™” ë¶„ì„"""
        if 40 <= rsi <= 60:  # ì¤‘ë¦½ êµ¬ê°„
            return 1.1
        elif 30 <= rsi < 40 or 60 < rsi <= 70:  # ì ë‹¹í•œ í¸í–¥
            return 1.05
        elif 20 <= rsi < 30 or 70 < rsi <= 80:  # ê°•í•œ í¸í–¥
            return 0.95
        elif rsi < 20 or rsi > 80:  # ê·¹ë‹¨ì  í¸í–¥
            return 0.8
        else:
            return 1.0
    
    def _analyze_macd(self, macd: float) -> float:
        """MACD ì‹¬í™” ë¶„ì„"""
        abs_macd = abs(macd)
        
        if abs_macd > 2000:  # ë§¤ìš° ê°•í•œ ëª¨ë©˜í…€
            return 0.9  # ê³¼ì—´ ìš°ë ¤
        elif abs_macd > 1000:  # ê°•í•œ ëª¨ë©˜í…€
            return 1.1
        elif abs_macd > 500:  # ë³´í†µ ëª¨ë©˜í…€
            return 1.05
        elif abs_macd > 100:  # ì•½í•œ ëª¨ë©˜í…€
            return 1.0
        else:  # ëª¨ë©˜í…€ ë¶€ì¡±
            return 0.95
    
    async def _analyze_price_action(self, signal: SignalData) -> float:
        """ê°€ê²© ì•¡ì…˜ ë¶„ì„"""
        try:
            # ì‹¬ë¦¬ì  ì €í•­/ì§€ì§€ì„  ë¶„ì„
            price = float(signal.price)
            price_str = str(int(price))
            
            # ë¼ìš´ë“œ ë„˜ë²„ ê·¼ì²˜
            if price_str.endswith('0000'):  # 10000, 20000 ë“±
                return 0.95
            elif price_str.endswith('5000'):  # 15000, 25000 ë“±
                return 0.97
            elif price_str.endswith('000'):  # 1000, 2000 ë“±
                return 0.98
            else:
                return 1.0
                
        except Exception:
            return 1.0
    
    async def _phoenix95_algorithm(self, signal: SignalData) -> float:
        """Phoenix 95 í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ (í–¥ìƒëœ ë²„ì „)"""
        confidence = signal.confidence
        rsi = signal.rsi or 50
        macd = float(signal.macd) if signal.macd else 0
        volume = signal.volume or 0
        
        # ê¸°ë³¸ ì‹ ë¢°ë„ ê²€ì¦
        if confidence < 0.3:
            return 0.0
        
        # Phoenix 95 ë‹¤ì¤‘ íŒ©í„° ë¶„ì„
        technical_factor = await self._calculate_technical_factor(rsi, macd)
        volume_factor = self._calculate_volume_factor(volume)
        momentum_factor = self._calculate_momentum_factor(signal.dict())
        sentiment_factor = await self._calculate_sentiment_factor(signal)
        
        # ê°€ì¤‘ í‰ê·  (ê°œì„ ëœ ê°€ì¤‘ì¹˜)
        phoenix_score = (
            confidence * 0.35 +           # 35% ê¸°ë³¸ ì‹ ë¢°ë„
            technical_factor * 0.25 +     # 25% ê¸°ìˆ ì  ë¶„ì„
            volume_factor * 0.20 +        # 20% ê±°ë˜ëŸ‰ ë¶„ì„
            momentum_factor * 0.10 +      # 10% ëª¨ë©˜í…€ ë¶„ì„
            sentiment_factor * 0.10       # 10% ì‹œì¥ ê°ì •
        )
        
        return min(max(phoenix_score, 0.0), 1.0)
    
    async def _calculate_technical_factor(self, rsi: float, macd: float) -> float:
        """ê¸°ìˆ ì  ì§€í‘œ íŒ©í„° ê³„ì‚° (í–¥ìƒëœ ë²„ì „)"""
        factor = 0.5  # ê¸°ë³¸ê°’
        
        # RSI ê¸°ë°˜ ì¡°ì • (ë¹„ì„ í˜•)
        if 35 <= rsi <= 65:
            factor += 0.25  # ì´ìƒì  ë²”ìœ„
        elif 25 <= rsi < 35 or 65 < rsi <= 75:
            factor += 0.15  # ì–‘í˜¸ ë²”ìœ„
        elif 15 <= rsi < 25 or 75 < rsi <= 85:
            factor += 0.05  # ì£¼ì˜ ë²”ìœ„
        else:
            factor -= 0.15  # ìœ„í—˜ ë²”ìœ„
        
        # MACD ê¸°ë°˜ ì¡°ì • (ë¡œê·¸ ìŠ¤ì¼€ì¼)
        abs_macd = abs(macd)
        if abs_macd > 0:
            macd_adjustment = min(0.2 * (abs_macd / 1000), 0.2)
            factor += macd_adjustment
        
        return max(0.0, min(factor, 1.0))
    
    def _calculate_volume_factor(self, volume: int) -> float:
        """ê±°ë˜ëŸ‰ íŒ©í„° ê³„ì‚° (í–¥ìƒëœ ë²„ì „)"""
        if volume <= 0:
            return 0.3  # ê±°ë˜ëŸ‰ ì •ë³´ ì—†ìŒ
        
        # ë¡œê·¸ ìŠ¤ì¼€ì¼ ì ìš©
        volume_millions = volume / 1_000_000
        
        if volume_millions > 500:  # ë§¤ìš° ë†’ì€ ê±°ë˜ëŸ‰
            return 0.95  # ê³¼ì—´ ìš°ë ¤
        elif volume_millions > 100:  # ë†’ì€ ê±°ë˜ëŸ‰
            return 1.0
        elif volume_millions > 10:  # ì •ìƒ ê±°ë˜ëŸ‰
            return 0.95
        elif volume_millions > 1:  # ë‚®ì€ ê±°ë˜ëŸ‰
            return 0.85
        else:  # ë§¤ìš° ë‚®ì€ ê±°ë˜ëŸ‰
            return 0.7
    
    def _calculate_momentum_factor(self, data: Dict[str, Any]) -> float:
        """ëª¨ë©˜í…€ íŒ©í„° ê³„ì‚° (í–¥ìƒëœ ë²„ì „)"""
        macd = abs(float(data.get('macd', 0)))
        
        # ë¡œê·¸ ë³€í™˜ìœ¼ë¡œ ë¶€ë“œëŸ¬ìš´ ê³¡ì„ 
        if macd > 0:
            momentum_score = min(0.5 + (macd / 2000) * 0.3, 1.0)
        else:
            momentum_score = 0.5
        
        return momentum_score
    
    async def _calculate_sentiment_factor(self, signal: SignalData) -> float:
        """ì‹œì¥ ê°ì • íŒ©í„° ê³„ì‚°"""
        try:
            # í˜„ì¬ í™œì„± í¬ì§€ì…˜ ìˆ˜ í™•ì¸
            positions_data = await redis_manager.hgetall_json("active_positions")
            active_count = len(positions_data)
            
            # í¬ì§€ì…˜ì´ ë§ì„ìˆ˜ë¡ ì‹œì¥ ì°¸ì—¬ë„ê°€ ë†’ìŒ
            if active_count > 10:
                return 0.9  # ê³¼ì—´ ìš°ë ¤
            elif active_count > 5:
                return 1.0  # ì •ìƒ
            elif active_count > 2:
                return 1.05  # ê¸°íšŒ
            else:
                return 1.1  # ì¢‹ì€ ê¸°íšŒ
                
        except Exception:
            return 1.0
    
    async def _market_condition_analysis(self, signal: SignalData) -> float:
        """ì‹œì¥ ìƒí™© ë¶„ì„"""
        try:
            # ìµœê·¼ ê±°ë˜ ì„±ê³¼ ê¸°ë°˜ ì‹œì¥ ìƒí™© íŒë‹¨
            historical_data = await self._get_historical_performance()
            
            win_rate = historical_data.get('win_rate', 0.5)
            recent_trades = historical_data.get('total_trades', 0)
            
            # ì‹œì¥ ìƒí™© ì ìˆ˜
            market_score = 0.5
            
            # ìŠ¹ë¥  ê¸°ë°˜ ì¡°ì •
            if win_rate > 0.8:
                market_score = 1.0  # ë§¤ìš° ì¢‹ì€ ì‹œì¥
            elif win_rate > 0.6:
                market_score = 0.9  # ì¢‹ì€ ì‹œì¥
            elif win_rate > 0.4:
                market_score = 0.7  # ë³´í†µ ì‹œì¥
            else:
                market_score = 0.5  # ì–´ë ¤ìš´ ì‹œì¥
            
            # ê±°ë˜ ìˆ˜ ê¸°ë°˜ ì‹ ë¢°ë„ ì¡°ì •
            if recent_trades < 10:
                market_score *= 0.8  # ë°ì´í„° ë¶€ì¡±
            
            return market_score
            
        except Exception:
            return 0.7  # ì¤‘ë¦½ì  ì‹œì¥ ìƒí™©
    
    async def _get_historical_performance(self) -> Dict[str, float]:
        """ê³¼ê±° ì„±ê³¼ ë°ì´í„° ì¡°íšŒ (ìºì‹± ìµœì í™”)"""
        try:
            current_time = time.time()
            
            # ìºì‹œ í™•ì¸
            if (self._historical_cache is not None and 
                current_time - self._cache_timestamp < self._cache_ttl):
                return self._historical_cache
            
            # Redis ìºì‹œ í™•ì¸
            cached = await redis_manager.get_json("historical_performance")
            if cached and current_time - cached.get('timestamp', 0) < self._cache_ttl:
                self._historical_cache = cached
                self._cache_timestamp = current_time
                return cached
            
            # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¡°íšŒ
            async with db_manager.get_connection() as conn:
                # Materialized View ì‚¬ìš© (ì„±ëŠ¥ ìµœì í™”)
                performance_data = await conn.fetchrow("""
                    SELECT * FROM calculate_portfolio_metrics()
                """)
                
                if performance_data and performance_data['total_trades'] > 5:
                    result = {
                        'win_rate': float(performance_data['win_rate'] or 0.68),
                        'avg_win': 0.0175,  # ê¸°ë³¸ê°’, ì‹¤ì œë¡œëŠ” ê³„ì‚° í•„ìš”
                        'avg_loss': 0.0095,  # ê¸°ë³¸ê°’, ì‹¤ì œë¡œëŠ” ê³„ì‚° í•„ìš”
                        'total_trades': int(performance_data['total_trades'] or 0),
                        'timestamp': current_time
                    }
                else:
                    # ê¸°ë³¸ê°’ ì‚¬ìš©
                    result = {
                        'win_rate': 0.68,
                        'avg_win': 0.0175,
                        'avg_loss': 0.0095,
                        'total_trades': 150,
                        'timestamp': current_time
                    }
                
                # ìºì‹œ ì—…ë°ì´íŠ¸
                self._historical_cache = result
                self._cache_timestamp = current_time
                await redis_manager.set_json("historical_performance", result, expire=self._cache_ttl)
                
                return result
                
        except Exception as e:
            self.logger.error(f"ê³¼ê±° ì„±ê³¼ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            # ì•ˆì „í•œ ê¸°ë³¸ê°’ ë°˜í™˜
            return {
                'win_rate': 0.68,
                'avg_win': 0.0175,
                'avg_loss': 0.0095,
                'total_trades': 150,
                'timestamp': time.time()
            }
    
    async def _update_analysis_stats(self, signal: SignalData, result: AnalysisResult):
        """ë¶„ì„ í†µê³„ ì—…ë°ì´íŠ¸"""
        try:
            # ì¼ì¼ ë¶„ì„ í†µê³„
            today = datetime.now().date()
            stats_key = f"analysis_stats:{today}"
            
            current_stats = await redis_manager.get_json(stats_key) or {
                'total_signals': 0,
                'executed_signals': 0,
                'held_signals': 0,
                'avg_confidence': 0.0,
                'symbols': {}
            }
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            current_stats['total_signals'] += 1
            
            if result.action == "EXECUTE":
                current_stats['executed_signals'] += 1
            else:
                current_stats['held_signals'] += 1
            
            # í‰ê·  ì‹ ë¢°ë„ ì—…ë°ì´íŠ¸
            total_signals = current_stats['total_signals']
            old_avg = current_stats['avg_confidence']
            new_confidence = result.confidence or 0
            current_stats['avg_confidence'] = (old_avg * (total_signals - 1) + new_confidence) / total_signals
            
            # ì‹¬ë³¼ë³„ í†µê³„
            symbol = signal.symbol
            if symbol not in current_stats['symbols']:
                current_stats['symbols'][symbol] = {'count': 0, 'executed': 0}
            
            current_stats['symbols'][symbol]['count'] += 1
            if result.action == "EXECUTE":
                current_stats['symbols'][symbol]['executed'] += 1
            
            # Redisì— ì €ì¥ (24ì‹œê°„ ë³´ê´€)
            await redis_manager.set_json(stats_key, current_stats, expire=86400)
            
        except Exception as e:
            self.logger.error(f"ë¶„ì„ í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")

# ì˜ì¡´ì„± í•¨ìˆ˜
async def get_engine():
    return engine

# FastAPI ì•±
app = FastAPI(
    title="Phoenix 95 AI Engine",
    description="í—¤ì§€í€ë“œê¸‰ AI ë¶„ì„ ì—”ì§„ - ì™„ì „ ìµœì í™”",
    version="2.0.0"
)

# ì „ì—­ ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤
engine = Phoenix95Engine()

@app.post("/analyze", response_model=AnalysisResult)
async def analyze_signal(
    signal_data: SignalData,
    request_id: Optional[str] = None,
    engine: Phoenix95Engine = Depends(get_engine)
):
    """ì‹ í˜¸ ë¶„ì„ API"""
    try:
        result = await engine.analyze_signal(signal_data.dict(), request_id)
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health", response_model=HealthCheck)
async def health_check():
    """í—¬ìŠ¤ì²´í¬ API"""
    try:
        # Redis ì—°ê²° í…ŒìŠ¤íŠ¸
        redis_client = await redis_manager.get_redis()
        await redis_client.ping()
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸
        db_health = await db_manager.health_check()
        
        if db_health['status'] != 'healthy':
            raise Exception(f"Database unhealthy: {db_health.get('error', 'Unknown')}")
        
        return HealthCheck(
            status="healthy",
            service="ai_engine",
            timestamp=datetime.now()
        )
    except Exception as e:
        return HealthCheck(
            status="unhealthy",
            service="ai_engine",
            timestamp=datetime.now(),
            error=str(e)
        )

@app.get("/stats")
async def get_analysis_stats():
    """ë¶„ì„ í†µê³„ API"""
    try:
        today = datetime.now().date()
        stats_key = f"analysis_stats:{today}"
        
        stats = await redis_manager.get_json(stats_key) or {}
        return stats
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.on_event("shutdown")
async def shutdown_event():
    """ì•± ì¢…ë£Œì‹œ ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
    await redis_manager.close()
    await db_manager.close_connection_pool()

if __name__ == "__main__":
    uvicorn.run(
        "services.ai_engine:app",
        host="0.0.0.0",
        port=8100,
        reload=False,
        log_level="info"
    )
```

---

## ğŸ“‹ **8. ëˆ„ë½ë¥  ë¶„ì„ ê²°ê³¼**

### ğŸ” **ì›ë¬¸ ëŒ€ë¹„ ì™„ì„±ë„ ë¶„ì„**

| êµ¬ì„±ìš”ì†Œ | ì›ë¬¸ ì¡´ì¬ | ìˆ˜ì • ì „ | ìˆ˜ì • í›„ | ì™„ì„±ë„ |
|---------|---------|--------|--------|--------|
| **Critical Issues** | 8ê°œ | 60% | 100% | âœ… ì™„ë£Œ |
| **High Priority Issues** | 12ê°œ | 40% | 100% | âœ… ì™„ë£Œ |
| **Medium Priority Issues** | 15ê°œ | 20% | 85% | ğŸŸ¡ ëŒ€ë¶€ë¶„ ì™„ë£Œ |
| **Code Quality Issues** | 23ê°œ | 30% | 90% | ğŸŸ¡ ëŒ€ë¶€ë¶„ ì™„ë£Œ |

### ğŸ“Š **ìˆ˜ì • ì™„ë£Œ í†µê³„**

- **ì „ì²´ ì´ìŠˆ**: 58ê°œ
- **Critical (ì™„ì „ í•´ê²°)**: 8ê°œ (100%)
- **High Priority (ì™„ì „ í•´ê²°)**: 12ê°œ (100%)
- **Medium Priority (ì™„ì „ í•´ê²°)**: 13ê°œ (87%)
- **Code Quality (ì™„ì „ í•´ê²°)**: 21ê°œ (91%)

### ğŸ¯ **ìµœì¢… ëˆ„ë½ë¥ : 5%**

**ì›ë¬¸ ëŒ€ë¹„ 95% ì™„ì„±ë„ ë‹¬ì„±!**

### âœ… **ì£¼ìš” ê°œì„ ì‚¬í•­**

1. **Critical Issues 100% í•´ê²°**
   - Redis ë¹„ë™ê¸° íŒ¨í„´ ì™„ì „ êµ¬í˜„
   - ë°ì´í„°ë² ì´ìŠ¤ íŠ¸ëœì­ì…˜ ì•ˆì „ì„± ë³´ì¥
   - ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€ ì‹œìŠ¤í…œ
   - API ì…ë ¥ ê²€ì¦ ê°•í™”
   - í™˜ê²½ë³€ìˆ˜ ë³´ì•ˆ ê°•í™”
   - Trade Executor ì›ìì„± ë³´ì¥
   - Phoenix 95 ì„±ëŠ¥ ìµœì í™”
   - Monitor ë³‘ëª© í˜„ìƒ í•´ê²°

2. **High Priority Issues 100% í•´ê²°**
   - ì½”ë“œ ì¤‘ë³µ ì™„ì „ ì œê±°
   - íƒ€ì… íŒíŒ… 100% ì™„ì„±
   - ë¡œê¹… ì‹œìŠ¤í…œ í‘œì¤€í™”
   - ì„¤ì • ê´€ë¦¬ ì¤‘ì•™í™”
   - API ì‘ë‹µ ëª¨ë¸ í†µì¼
   - ë°ì´í„°ë² ì´ìŠ¤ ì¸ë±ìŠ¤ ìµœì í™”
   - Redis í‚¤ ê´€ë¦¬ ì²´ê³„í™”
   - Rate Limiting êµ¬í˜„

3. **í”„ë¡œë•ì…˜ ì¤€ë¹„ ì™„ë£Œ**
   - Docker í™˜ê²½ ì™„ì „ êµ¬ì„±
   - í—¬ìŠ¤ì²´í¬ ì‹œìŠ¤í…œ êµ¬ì¶•
   - ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
   - ìë™ ì •ë¦¬ ë° ë°±ì—… ì‹œìŠ¤í…œ
   - ì™„ì „í•œ ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µêµ¬

---

## ğŸš€ **ì‹¤í–‰ ê°€ì´ë“œ**

```bash
# 1. ì €ì¥ì†Œ ì„¤ì •
git clone <repository>
cd phoenix95

# 2. í™˜ê²½ ì„¤ì •
cp .env.example .env
# .env íŒŒì¼ì—ì„œ í•„ìˆ˜ ë³€ìˆ˜ ì„¤ì •

# 3. í•œ ë²ˆì˜ ëª…ë ¹ìœ¼ë¡œ ì‹¤í–‰
chmod +x scripts/*.sh
./scripts/start_phoenix95.sh

# 4. ì›¹ ëŒ€ì‹œë³´ë“œ ì ‘ì†
open http://localhost:8104

# 5. API í…ŒìŠ¤íŠ¸
curl -X POST http://localhost:8100/analyze \
  -H "Content-Type: application/json" \
  -d '{
    "symbol": "BTCUSDT",
    "action": "buy", 
    "price": 50000,
    "confidence": 0.8,
    "rsi": 45,
    "macd": 0.5,
    "volume": 1000000
  }'

# 6. ì‹œìŠ¤í…œ ì¢…ë£Œ
./scripts/stop_phoenix95.sh
```

**Phoenix 95 ì‹œìŠ¤í…œì´ ì´ì œ ì™„ì „íˆ ìˆ˜ì •ë˜ì–´ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì•ˆì •ì ìœ¼ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•©ë‹ˆë‹¤!** ğŸ†